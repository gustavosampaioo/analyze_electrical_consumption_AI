import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import google.generativeai as generai

# Configura√ß√£o inicial
st.set_page_config(page_title="An√°lise de Consumo de Energia", layout="wide")
st.title("üîç An√°lise de Consumo de Energia com Detec√ß√£o de Fraude")

# Configura√ß√£o da API do Google Generative AI
generai.configure(api_key="SUA_CHAVE_DE_API_AQUI")  # Substitua pela sua chave API

# Fun√ß√£o para carregar dados
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("dados_consumo.csv")
        return df
    except FileNotFoundError:
        st.error("Arquivo 'dados_consumo.csv' n√£o encontrado.")
        return None

# Fun√ß√£o para an√°lise com IA generativa
def analyze_with_ai(data_summary, metrics):
    model = generai.GenerativeModel("gemini-1.5-flash-latest")
    
    prompt = f"""
    Voc√™ √© um especialista em an√°lise de dados de consumo de energia e detec√ß√£o de fraudes. 
    Analise os seguintes dados e m√©tricas:

    **Resumo dos dados:**
    {data_summary}

    **M√©tricas do modelo:**
    {metrics}

    Sua an√°lise deve conter:
    1. Padr√µes de consumo de energia identificados
    2. Interpreta√ß√£o profissional das m√©tricas de avalia√ß√£o
    3. An√°lise da matriz de confus√£o
    4. Recomenda√ß√µes para melhorar a detec√ß√£o
    5. Per√≠odos de maior risco de fraude
    
    Formate a resposta em markdown com t√≠tulos e bullet points.
    """
    
    response = model.generate_content(prompt)
    return response.text

# Fun√ß√£o principal
def main():
    df = load_data()
    
    if df is not None:
        st.sidebar.header("Configura√ß√µes")
        show_raw_data = st.sidebar.checkbox("Mostrar dados brutos")
        
        if show_raw_data:
            st.subheader("Dados de Consumo")
            st.dataframe(df)
        
        # An√°lise explorat√≥ria
        st.subheader("üìä An√°lise Explorat√≥ria")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Consumo M√©dio Di√°rio**")
            st.line_chart(df.set_index('data')['consumo_medio_diario'])
        
        with col2:
            st.write("**Consumo M√≠nimo Noturno**")
            st.bar_chart(df.set_index('data')['consumo_minimo_noturno'])
        
        # Pr√©-processamento
        features = df.iloc[:, 1:25]  # Colunas h1-h24
        target = df['status_fraude']
        
        # Divis√£o treino-teste
        X_train, X_test, y_train, y_test = train_test_split(
            features, target, test_size=0.3, random_state=42
        )
        
        # Modelagem
        model = RandomForestClassifier(random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        # M√©tricas
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        cm = confusion_matrix(y_test, y_pred)
        
        # Exibi√ß√£o de m√©tricas
        st.subheader("üìà M√©tricas de Avalia√ß√£o do Modelo")
        
        metrics_col1, metrics_col2 = st.columns(2)
        
        with metrics_col1:
            st.metric("Acur√°cia", f"{accuracy:.2%}")
            st.metric("Precis√£o", f"{precision:.2%}")
            st.metric("Recall", f"{recall:.2%}")
        
        with metrics_col2:
            st.write("**Matriz de Confus√£o**")
            fig, ax = plt.subplots()
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                        xticklabels=['Normal', 'Fraude'], 
                        yticklabels=['Normal', 'Fraude'])
            plt.ylabel('Verdadeiro')
            plt.xlabel('Predito')
            st.pyplot(fig)
        
        st.write("**Relat√≥rio de Classifica√ß√£o**")
        st.text(classification_report(y_test, y_pred))
        
        # An√°lise com IA generativa
        if st.button("üß† Obter An√°lise Avan√ßada com Gemini"):
            with st.spinner("Analisando dados com Gemini 1.5 Flash..."):
                try:
                    # Preparar resumo dos dados
                    data_summary = df.describe().to_string()
                    
                    # Preparar m√©tricas
                    metrics = f"""
                    - Acur√°cia: {accuracy:.2%}
                    - Precis√£o: {precision:.2%}
                    - Recall: {recall:.2%}
                    - Matriz de Confus√£o: \n{cm}
                    - Relat√≥rio: \n{classification_report(y_test, y_pred)}
                    """
                    
                    # Chamar a API do Google
                    analysis = analyze_with_ai(data_summary, metrics)
                    
                    st.subheader("üìù An√°lise com Gemini 1.5 Flash")
                    st.markdown(analysis)
                except Exception as e:
                    st.error(f"Erro na an√°lise com Gemini: {str(e)}")
        
        # Se√ß√£o de interpreta√ß√£o
        st.subheader("üîç Guia de Interpreta√ß√£o")
        with st.expander("Como interpretar essas m√©tricas?"):
            st.markdown("""
            **Acur√°cia** (Accuracy):  
            > Porcentagem total de previs√µes corretas. √ötil para conjuntos balanceados, mas pode enganar em casos desbalanceados.

            **Precis√£o** (Precision):  
            > Dos alertas de fraude emitidos, quantos eram realmente fraudes. Alta precis√£o significa poucos falsos positivos.

            **Recall** (Sensibilidade):  
            > Das fraudes reais existentes, quantas foram detectadas. Alto recall significa poucos falsos negativos.

            **Matriz de Confus√£o**:
            - **TP** (True Positive): Fraudes detectadas corretamente
            - **FP** (False Positive): Consumos normais erroneamente classificados como fraude
            - **TN** (True Negative): Consumos normais corretamente identificados
            - **FN** (False Negative): Fraudes que passaram despercebidas

            **Trade-off Importante**:  
            > Aumentar a precis√£o (reduzir FP) geralmente reduz o recall (aumenta FN), e vice-versa.
            """)

if __name__ == "__main__":
    main()
